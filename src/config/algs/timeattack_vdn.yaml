# Q-learning with ODE-based time attack
# === Algorithm ===
name: "timeattack_vdn"

# === Controller ===
mac: "basic_mac"
agent_output_type: "q"
action_selector: "epsilon_greedy"
epsilon_start: 1.0
epsilon_finish: 0.05
epsilon_anneal_time: 50000

# === Agent ===
agent: "rnn"
rnn_hidden_dim: 64
obs_agent_id: True
obs_last_action: True

# === Learner ===
learner: "q_learner"

# === VDN specific ===
double_q: True
mixer: "vdn"

# === Optimization ===
lr: 0.0005
optim_alpha: 0.99
optim_eps: 0.00001
grad_norm_clip: 10

# === RL hyperparameters ===
gamma: 0.99
batch_size: 32
target_update_interval: 200

# === Runner ===
runner: "episode"
batch_size_run: 1
test_nepisode: 20
test_interval: 2000
log_interval: 2000
runner_log_interval: 2000
learner_log_interval: 2000
t_max: 2050000

# === Time attack specific ===
use_ode_model: False
attack_duration: 5
trans_input_len: 20
num_attack_test: 8
num_attack_train: 12
num_followup_agents: 2


# === Transformer parameters ===
trans_embed_dim: 128
trans_num_heads: 8
trans_num_layers: 4
trans_dropout: 0.1
trans_ff_dim: 256
num_trans_layer: 4
num_trans_head: 8
trans_hidden_dim: 128
max_seq_length: 100

# === ODE Model parameters ===
ode_dims: 64
rec_dims: 32
augment_dim: 0
treatment_dim: 8
t_dim: 8
solver: "dopri5"
z0_encoder: "GCN"
rec_layers: 2
num_atoms: 5
output_dim: 30
dropout: 0.1
use_attention: 1
use_onehot: 0

# === Other ===
use_cuda: True
