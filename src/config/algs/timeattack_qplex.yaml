# Q-learning with ODE-based time attack
name: "timeattack_qplex"

# === Controller ===
mac: "basic_mac"
agent_output_type: "q"
action_selector: "epsilon_greedy"
epsilon_start: 1.0
epsilon_finish: 0.05
epsilon_anneal_time: 50000

# === Agent ===
agent: "rnn"
rnn_hidden_dim: 64
obs_agent_id: True
obs_last_action: True

# === Learner ===
learner: "ode_q_learner"  # Change to use ODE learner

# === QPLEX specific ===
double_q: True
mixer: "qplex"
mixing_embed_dim: 32
hypernet_layers: 2
hypernet_embed: 64

# === Optimization ===
lr: 0.0005
optim_alpha: 0.99
optim_eps: 0.00001
grad_norm_clip: 10
weight_decay: 0

# === RL hyperparameters ===
gamma: 0.99
batch_size: 32
buffer_size: 32
lr_decay_mode: None
target_update_interval: 200

# === Runner ===
runner: "episode"
batch_size_run: 1
test_nepisode: 20
test_interval: 2000
log_interval: 2000
runner_log_interval: 2000
learner_log_interval: 2000
t_max: 2050000

# === Logging ===
use_tensorboard: False
save_model: False
save_model_interval: 2000000
checkpoint_path: ""
evaluate: False
load_step: 0

# === Experimental ===
# Time attack specific parameters
use_ode_model: True  # Enable ODE models
attack_duration: 5
trans_input_len: 20
num_attack_test: 8
num_attack_train: 12
num_followup_agents: 2

# === Environment parameters ===
env_max_timestep: 1000
attack_period: 10

# === Transformer parameters ===
trans_embed_dim: 128
trans_num_heads: 8
trans_num_layers: 4
trans_dropout: 0.1
trans_ff_dim: 256
num_trans_layer: 4
num_trans_head: 8
trans_hidden_dim: 128
max_seq_length: 100

# === ODE Model parameters (when use_ode_model=True) ===
ode_dims: 64
rec_dims: 32
augment_dim: 0
treatment_dim: 8
t_dim: 8
solver: "dopri5"
z0_encoder: "GCN"
rec_layers: 2
num_atoms: 5
output_dim: 30
dropout: 0.1

# === Other missing parameters ===
use_attention: 1
use_onehot: 0

# === Other ===
use_cuda: True
